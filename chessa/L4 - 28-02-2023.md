The problem of interoperability arises between consortium of standards.  Nowadays, the problem of interoperability and thus of standarization is moving up at middleware/application layer.
For ZigBee, it covers many layers: it defines a network, transport and application layer specific for ZigBee and incompatible with others. 

When there are too may standard avaialble and they are not compatible, the solution is to use the concepts of *endpoints* or **integration gateways**: allows to translate from a given standard to another. The gateway is limited to a single layer but they're able to translate a layer protocol to another one.  

We have different scenarios/configurations:
![[Pasted image 20230228112347.png]]
In the left case, even if the same vendor with same protocol, the nodes need a communication to the service gateway that provides access to the internet.
In the right case, we have different vendors that commonly use the same protocol, respecting a common standard: even in this case we need the sservice gateway to access the rest of the world. The service gateway allows to map *the rest of the world* to interact with it. 

For devices that are not using internet, there is no need to provide external connectivty: differently for ZigBee or MQTT in which the service gateway provide the functionality of transmitting external data.
Different scenario is pictued here:
![[Pasted image 20230228112743.png]]

In the left scenario, we have 3 networks which talks using a common standard provided by the **integration gateway**: in each network, the node talk each other using specific protocols, different from network to network. 
A integration gateway is able to speak different languages/protocols and able to map one protoocol in another. The mapping can be complicated becase can define different behaviours of the devices: in case of a protocol that *push data* and other that differently *pop data* are not translable in one another. So the integration gateway need to translate the *behaviour*: it also need to complete the packet structure, frame tramission, etc. 

In type C/II scenario, the key idea is that the protocol standard or under-the-hood technology is driven by the players (*Google, Amazon*) that in practice determine the specific technology of *integration agteway*, pushing other players to develop in accordance to their technology to guarantee interoperability.

Provide a general purpose integration service is complex: a better solution is forming a *network* of integration gateway that allows to map one protocol to another one or subset of specific-translated protocol. So we obtain a network of **distributed integration gateways**:
![[Pasted image 20230228114110.png]]
### Brief Security in IoT
![[Pasted image 20230228114543.png]]
Some devices are constrained, unconstrained or provide security features: some of them, despite not having security features, they're connected directly with internet. 
A paper of 2014 poses to problem of security in IoT: the pressure of time-to-market and fasten development phases set the problem of security on devices that are constrained in terms of capabilities or powers so security sometimes became optional because it's not fittble in that types of devices.

Usually those devices are not capable to run a full-fledge OS but only a simple OS without security features that are necessary to implement policies, even during updating the software-specific features. 

The problem arises in the topics of *confidentiality* and *authentication* (*e.g. wearable, physiological sensors*).

##### Security Standards
The IUT-T standard recommendation includes a list of security requirements for the IoT: it describes functional requirements during capturing, storing and trasferring7processing data of things as well as provision services. The requirements concern:
 - **Communication security** (*secure, trusted, and privacy protected communication capabilities*): enforces confidentiality and integrity of data during data transmission or transfer
 - **Mutual authentication and authorization**: mutual authentication and authorization between devices (or device/user) according to predefined security policies. Before a device (or an IoT user) can access the IoT. The authentication pattern can follow 2 main methods:
	 - Remote: directly to the cloud but poses complexity due to device's constraints
	 - Local: between devices or authentication service at most one-hop far way or with low overhead for devices
	The mutual authentication is meant as *in both direction between devices and gateway*.

The **gateway** is the main building block of the security mechanism and the devices implement only a subset of logic in accordance to the security operations carried out by the gateway. 

Authentication can happen at different levels: authenticate devices only at physical layer is important but itself it's not a guarantee that the behaviour at the application level is correct (*e.g. tampered device at physical layer*).
There are also other features like protect privacy for devices and gateway, self-diagnosis and self-repair.
A critical phase is the deployment of the devices because initially they're not fully configured and may have not been still identified the correct gateway to connect. 

## MQTT - Message Queueing Telemetry Transport

MQTT covers application, session and presentation layer (*both directly or undirectly by using middleware*). 
MQTT uses an instance of *publish-subscribe* model between users and consumer: internally, as we will see, is implemented as a client-server architecture. 
To connect to internet, the IoT devices must adopt internet protocol suite. However, internet stack is too resource-compsuntive respect to constrained IoT devices that usually are *lossy, low power, etc*.

#### IoT Requirements
The IoT devices have different requirement based on given context and offered/requested features. 

- *Multi-hop/Mesh networking* allows to provide a connectivity and communication among shared group of devices. 
- Addressing: 

## MQTT intro
It's a lightweight publish/subscribe reliable messaging transport protocol. Lightweigth thanks to small code footprint and low network bandwidth, with minimal packet overhead (slightly better than TCP). 
It builds upon *TCP/IP* with port `1883` or `8883` for using MQTT with SSL (*with overhead*). 

Internally MQTT uses a **client/server** architecture: this bought the major complexities on the server side. Provide QoS and it's *data agnostic* so it's suitable both to M2M and IoT.

#### Publish/subscribe model
The main components of the model are **publishers, subscribers** and **broker or event service**. The fist two are both seen as clients and do not know each other, the latter it's the serer known both by publishers and consumer. 
The **publisher** produce event or any data: interact only with the **broker** and does not know if the data is consumed/read by other entities.
The subscribes express interest for an event (*or a pattern of events*): receive the notifications from the broker whenevr the event is generated.
Publishers and subscribers never interact each other: they interact indirectly only by the *broker(s)*. 
Those pattern allows to be publisher and subscriber to be decoupled in **time, space and syncrhonization**.

The broker know publisher/subscribers and receive all incoming messages from the first, filter them all and distributed them to the interested subscriber. It also need to manage request of subscription/unsubscription. 

A **publish/subscribe** interaction can be implented in different ways: the boker is usually an *independent* agent and manage, coordinating with publishers/subscribers, the operations of `publish, subscribe, notify, unsubscribe`. 
![[Pasted image 20230301091322.png]]
The **broker** is delegated to storage and management of subscriptions.  
Here an example in which different subscribers register themself to one or more *topics* (*smartphone wubscribe to `T&H` or temperature and humidity* while *computer subscribe only to temperature topic*). 
![[Pasted image 20230301091527.png]]

This model allow to **decouple the space** because pub/sub do not need to known each other and do not share anything (*they don't known the IP/port of each other and how many peers are subscribed*). It allows also the **time decoupling** because they don't need to run at the same time, guaranteeing the **asyncrhonicity** of the model. 
![[Pasted image 20230301091741.png]]

The decoupling increments the **scalability** of the actors involved: the operations on the broker can be easily parallelized and are event-driven, allowing scalability to a very large number of devices by parallelizing the broker. 

#### Filtering
The filtering features managed by the broker can be based on three different criteria:
- *Based on **subject topic***: the subject (*or topic*) is a part of the message and clients subscribe only to a specific topic. They are usually represented by a string, possible organized in a hierarchical taxonomy. 
- *Based on **content***: the client subscribe for a specific query (*like `temperature > 30Â°`*) and that query is used by the broker to filter the messages. This methods involves to understand the semantics of the data transmitted or at least be able to *read* the data so add complexity con context in which security mechanism (*like encryption*) are used to transmit/store data. 
- *Based on **type***: filtering of event is based on both *content* and *structure* so the type refers to the type/class of data that can be customized by the subscriber by defining in a strongly typed language the desired object structure. This methods introduces complexities in case publishers and subscribers are written in different language and there is no a unique *translation of type* because their type system is not uniquely determinate. In those scenarios tight integration of the middlewaew and language paradigms (*like Object Programming*) can ease the presented problem. 

#### Highlights
In the proposed model, publishers and subscriber **need to agree on topics beforehand** and publisher cannot assume that somebody is listening to the messages because is there are no subscriber messages are not readed by anyone. 
Despite pub/sub do not need to known each other, they need to known the *hostame/port* of the **broker** beforehand, to connect and establish a TCP connection to it.
In most application, the delivery of messages is near-real-time but in cases when the subscribers are offline, the broker is able to store the messages *only if* subscribers have been connected with a **persistent session** and they're already subscribed to the *topic*.  In case of delay or unreliable message the retransmissions is necssary and the latency issues have to been taken into account.
Also the deployment phase take time due to the time needed both by clients to connect to brokers.

MQTT decouples the syncrhonization allowing to obtain an *asyncrhonous model*: this model implies the use of callback functions on the subscriber side. Libraries that implements MQTT allows this async model by enabling callbacks.
The complexities of the MQTT protocol are shifted to the broker work which in general represent a much more powerful machine respect to subscribers/clients.

As mentioned, the *subject-based* filtering of a message involves the use of *topic*: topic is based on a hirerarchy of topics that are meaning to the purposes of the appication.
MQTT offers additional *QoS* in term of message reliability: it's based on top of TCP by adding an application level ackwnoledge. It's expressed by 3 levels of QoS (0, 1 ,2). 
The last two levels ensure the ACK at application level: the level 0 corresponds to TCP reliability level.

